# -*- coding: utf-8 -*-
"""Dropping features and calculate accuracy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DiCjRtliBM-Qge1J8Xiw_Lpxm45SGAND
"""

# This part is feature selection
# 1) Dropping each features individually, then use the rest of features to train linear regression model
# 2) Dropping features in pair, according to correlation. For example, week has strong relationship with season. Therefore, dropping these two features together
# 3) Saving the predicted value into a table
# 4) Calculate the accuracy of dropping features
# 5) This part contains five models (Linear regression, KNN, SVR, LSTM, transfer learning), but I only put linear regression and KNN models in this file to make the code more clear

# 1. Linear regression model, dropping each feature individually
list_a = ["Day","dayofmonth",'dayofweek','week','month','year','season','dayofyear','Easter','Christmas','Summer/winter_holiday','Halloween','Patrick',"maxtp","mintp","rain","cbl","wdsp"]
label = data_lough["Total"].astype(np.float64)
data = data_lough.drop('Total',1)
my_dict = pd.DataFrame({'Acctural_value': y_test})
for i in list_a:
    X_train, X_test, y_train, y_test = train_test_split(data.drop(i,1), label, test_size=0.2,random_state = 0)
    model2 = linear_model.LinearRegression()
#   train the model wit the rest of features
    model2.fit (X_train,y_train)
#   make prediction
    predict = model2.predict(X_test)
#   put all the result in a dataFrame
    my_dict[i]= predict
#   Saving the dataFrame in a final table.
my_dict.to_csv('/content/drive/My Drive/Colab Notebooks/lr_feature_comparison/linear_all.csv', index=False, header=True)

# calculate the accuracy of dropping features
my_dict.to_csv('/content/drive/My Drive/Colab Notebooks/lr_feature_comparison/linear_all.csv', index=False, header=True)
import matplotlib.pyplot as plt
from google.colab import drive
drive.mount('/content/drive')
!Is "/content/drive/My Drive/Colab Notebooks"
inputfile1 = '/content/drive/My Drive/Colab Notebooks/lr_feature_comparison/linear_all.csv'
linear_featuures = pd.read_csv(inputfile1, encoding="UTF-8")
# individual featrues
col_name = ['Acctural_value',	'without_Day',	'without_dayofmonth'	,'without_dayofweek',	'without_week'	,'without_month'	,'without_year'	,'without_season',	'without_dayofyear',	'without_Easter',	'without_Christmas',	'without_Summer/winter_holiday'	,'without_Halloween'	,'without_Patrick'	,'without_maxtp'	,'without_mintp',	'without_rain'	,'without_cbl'	,'without_wdsp']
# features in pair
col_name = ['Acctural_value', 'without_Day_year' , 'without_mintp_maxtp' , 'without_week_season'  ,'without_month_week']

def accuracy_lr(test):
    total = 0
    predict = linear_featuures['Acctural_value']
    for i in range(len(predict)):
        if abs(test) <= abs(predict[i]):
           a = abs(test) / abs(predict[i])
        else:
            a =  abs(predict[i]) / abs(test) 
        total += a
    accuracy = total / len(predict)
    return accuracy      
dataset = DataFrame({"Day":Day,"Total":filter_sd,'maxtp' : maxtp,'mintp' : mintp,'rain' : rain , 'cbl' : cbl, 'wdsp' : wdsp})
dict = {}
for i in col_name:
    x = linear_featuures[i].apply(lambda x: accuracy_lr(x))
    dict[i] =  x
new_dict = pd.DataFrame(dict,index = [0])
new_dict.to_csv('/content/drive/My Drive/Colab Notebooks/feature_comparision_with_all_features/linear_regression.csv')


# 2. KNN model, dropping each feature individually
list_a = ["Day","dayofmonth",'dayofweek','week','month','year','season','dayofyear','Easter','Christmas','Summer/winter_holiday','Halloween','Patrick',"maxtp","mintp","rain","cbl","wdsp"]
label = data_lough["Total"].astype(np.float64)
data = data_lough.drop('Total',1)
my_dict = pd.DataFrame({'Acctural_value': y_test})
for i in list_a:
    X_train, X_test, y_train, y_test = train_test_split(data.drop(i,1), label, test_size=0.2,random_state = 0)
#   add noise to y 
    y_train += 0.1 * np.random.rand(n_dots) - 0.1
#   set K is 5, calculate the closet 5 neigbours' value
    k = 5
    knn = KNeighborsRegressor(k)
    knn.fit(X_train,y_train)
#   make prediction
    y_pred = knn.predict(X_test)
#   put all the result in a dataFrame
    my_dict[i]= y_pred


# calculate the accuracy of dropping features
my_dict.to_csv('/content/drive/My Drive/Colab Notebooks/lr_feature_comparison/knn_all.csv', index=False, header=True)
import matplotlib.pyplot as plt
from google.colab import drive
drive.mount('/content/drive')
!Is "/content/drive/My Drive/Colab Notebooks"
inputfile1 = '/content/drive/My Drive/Colab Notebooks/lr_feature_comparison/knn_all.csv'
linear_featuures = pd.read_csv(inputfile1, encoding="UTF-8")
# individual featrues
col_name = ['Acctural_value',	'without_Day',	'without_dayofmonth'	,'without_dayofweek',	'without_week'	,'without_month'	,'without_year'	,'without_season',	'without_dayofyear',	'without_Easter',	'without_Christmas',	'without_Summer/winter_holiday'	,'without_Halloween'	,'without_Patrick'	,'without_maxtp'	,'without_mintp',	'without_rain'	,'without_cbl'	,'without_wdsp']
# features in pair
col_name = ['Acctural_value', 'without_Day_year' , 'without_mintp_maxtp' , 'without_week_season'  ,'without_month_week']

def accuracy_lr(test):
    total = 0
    predict = linear_featuures['Acctural_value']
    for i in range(len(predict)):
        if abs(test) <= abs(predict[i]):
           a = abs(test) / abs(predict[i])
        else:
            a =  abs(predict[i]) / abs(test) 
        total += a
    accuracy = total / len(predict)
    return accuracy      
dataset = DataFrame({"Day":Day,"Total":filter_sd,'maxtp' : maxtp,'mintp' : mintp,'rain' : rain , 'cbl' : cbl, 'wdsp' : wdsp})
dict = {}
for i in col_name:
    x = linear_featuures[i].apply(lambda x: accuracy_lr(x))
    dict[i] =  x
new_dict = pd.DataFrame(dict,index = [0])
new_dict.to_csv('/content/drive/My Drive/Colab Notebooks/feature_comparision_with_all_features/knn.csv')